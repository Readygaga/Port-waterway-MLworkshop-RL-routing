{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete, Sequence\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "\n",
    "#import helpers\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import tensorboard\n",
    "import pygame\n",
    "import pylab\n",
    "from pygame.locals import *\n",
    "import time\n",
    "\n",
    "# import stable_baselines3\n",
    "from stable_baselines3 import PPO, SAC, A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "#render related\n",
    "\n",
    "\n",
    "# routing related\n",
    "import networkx as nx\n",
    "from statistics import mode\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import main\n",
    "import NSGA\n",
    "from main import Graph, FishGround, FishFactory, WayPoint, Start, End, Position, great_circle_distance, scgraph_distance, pathRisk, pathCatch, pathGain, pathFuel, pathDistance, Ship, dynamic_routing\n",
    "\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "graph1 = Graph(G)\n",
    "loc1 = FishGround(name='FG1', location=Position(30, 15), fishstock={'Sei':{'quantity':100, 'timewindow':(1, 2)}})\n",
    "loc2 = FishGround(name='FG2', location=Position(30, 50), fishstock={'Sei':{'quantity':500, 'timewindow':(1, 2)}})\n",
    "loc3 = FishGround(name='FG3', location=Position(60, 50), fishstock={'Sei':{'quantity':300, 'timewindow':(1, 2)}})\n",
    "start = Start(name='S', location=Position(10, 10))\n",
    "end = End(name='E', location=Position(80, 80))\n",
    "ff1 = FishFactory(name='FF1', location=Position(50, 60))\n",
    "ff2 = FishFactory(name='FF2', location=Position(70, 50))\n",
    "\n",
    "\n",
    "locations = [start, loc1, loc2, loc3, ff1, ff2, end]\n",
    "graph1.addlocations_2(locations=locations)\n",
    "ship = Ship(targeted_fish='Cod', targeted_quantity=1000, weight=1000)\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import matplotlib.backends.backend_agg as agg\n",
    "class Routing(Env):\n",
    "    def __init__(self, Graph:Graph, Ship:Ship, start):\n",
    "        self.ship = Ship\n",
    "        self.graph = Graph\n",
    "        self.Footprint = nx.DiGraph()\n",
    "        self.Footprint.add_node(start)\n",
    "        nodeattr = self.graph.graph.nodes[start].copy()\n",
    "        nx.set_node_attributes(self.Footprint, {start: nodeattr})\n",
    "        self.successorsLst = nx.dfs_successors(G=self.graph.graph, source=start, depth_limit=1)[start]\n",
    "        self.action_space = MultiDiscrete([7, 100, 10])\n",
    "        #old_action_space=Dict({'location_to_go': Discrete(len(self.successorsLst)), 'speed': Box(low=0, high=30, shape=(1,)), 'duration': Box(0, 10, shape=(1,))})\n",
    "        self.observation_space = Dict({'route': Discrete(7), 'Speed': Discrete(100), 'Duration': Discrete(10), 'pathDistance': Box(low=0, high=30000, shape=(1,), dtype=float)})\n",
    "        self.current_place = start\n",
    "        locations.index(start)\n",
    "        self.state = {'route': locations.index(start), 'Speed': 0, 'Duration': 0, 'pathDistance': 0}\n",
    "        self.route_state = {'footprint': self.Footprint, 'route': [start], 'Speed': [], 'Duration': []}\n",
    "        self.previous_place = None\n",
    "        self.route_length = 16\n",
    "\n",
    "    def step(self, action):\n",
    "        #print(action[0])\n",
    "        #print('successors:', [loc.name for loc in self.successorsLst])\n",
    "        location = locations[action[0]]\n",
    "        #print(location.name)\n",
    "        self.previous_place = self.current_place\n",
    "        if location in self.successorsLst:\n",
    "            #Update state, including Footprint, route, speed and duration\n",
    "            self.current_place = location\n",
    "            self.route_state['route'].append(self.current_place)\n",
    "            self.route_state['Speed'].append(action[1])\n",
    "            self.route_state['Duration'].append(action[2])\n",
    "            nodeattr = self.graph.graph.nodes[self.current_place].copy()\n",
    "            nodeattr['Duration'] = action[2]\n",
    "            self.Footprint.add_node(self.current_place)\n",
    "            nx.set_node_attributes(self.Footprint, {self.current_place: nodeattr})\n",
    "            self.Footprint.add_edge(self.previous_place, self.current_place)\n",
    "            edgeattr = self.graph.graph.edges[(self.previous_place, self.current_place)].copy()\n",
    "            edgeattr['Speed'] = action[1]\n",
    "            nx.set_edge_attributes(self.Footprint, {(self.previous_place, self.current_place): edgeattr})\n",
    "            if not isinstance(self.current_place, End):\n",
    "                successors = nx.dfs_successors(G=self.graph.graph, source=self.current_place, depth_limit=1)\n",
    "                self.successorsLst = successors[self.current_place]\n",
    "            #print('current_place', self.current_place.name)\n",
    "            #rewards\n",
    "            path = self.route_state['route']\n",
    "            distance = self.Footprint.edges[(self.previous_place, self.current_place)]['distance'] #pathDistance(G=self.Footprint, path=path)\n",
    "            #print(distance)\n",
    "            padistance = pathDistance(G=self.Footprint, path=path)\n",
    "            self.state = {'route': action[0], 'Speed': action[1], 'Duration': action[2], 'pathDistance': padistance}\n",
    "            reward = -padistance\n",
    "        else:\n",
    "            self.state = {'route': locations.index(self.previous_place), 'Speed': action[1], 'Duration': action[2], 'pathDistance': -10000000}\n",
    "            reward = -10000000\n",
    "        info = {}\n",
    "\n",
    "        self.route_length -= 1\n",
    "        # conditions to end episode\n",
    "        if self.route_length <= 0 or isinstance(self.current_place, End):\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        #print('steps', self.route_length)\n",
    "        #print('obs', self.state)\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "    def render(self):\n",
    "        fig = pylab.figure(figsize=[4, 4],  # Inches\n",
    "                           dpi=200,  # 100 dots per inch, so the resulting buffer is 400x400 pixels\n",
    "                           )\n",
    "        fig.gca()\n",
    "        self.graph.plot_graph()\n",
    "        width = [self.Footprint[u][v]['Speed'] if self.Footprint[u][v]['Speed'] <= 10 else 10 for u, v in self.Footprint.edges()]\n",
    "        pos = {n: [n.position[1], n.position[0]] for n in list(self.Footprint.nodes())}\n",
    "        nx.draw_networkx(self.Footprint, with_labels=False, pos=pos, node_color='red', edge_color='red', width=width,\n",
    "                         font_color='red')\n",
    "        pos_for_speed = {n: [n.position[1] - 5, n.position[0] - 5] for n in list(self.Footprint.nodes())}\n",
    "        nx.draw_networkx_edge_labels(self.Footprint, pos_for_speed,\n",
    "                                     edge_labels={(u, v): \"Speed:{:.0f}\".format(d['Speed']) for u, v, d in\n",
    "                                                  self.Footprint.edges(data=True)}, font_color='red')\n",
    "        nodes = []\n",
    "        for node in list(self.Footprint.nodes()):\n",
    "            state = isinstance(node, Start) or isinstance(node, End)\n",
    "            if state is False:\n",
    "                nodes.append(node)\n",
    "        nx.draw_networkx_labels(self.Footprint, pos_for_speed,\n",
    "                                labels={n: \"Duration:{:.0f}\".format(self.Footprint.nodes[n]['Duration']) for n in nodes},\n",
    "                                font_color='red',\n",
    "                                font_size=9,\n",
    "                                horizontalalignment='center')\n",
    "\n",
    "        canvas = agg.FigureCanvasAgg(fig)\n",
    "        canvas.draw()\n",
    "        renderer = canvas.get_renderer()\n",
    "        raw_data = renderer.tostring_rgb()\n",
    "        window = pygame.display.set_mode((800, 800), DOUBLEBUF)\n",
    "        screen = pygame.display.get_surface()\n",
    "\n",
    "        size = canvas.get_width_height()\n",
    "\n",
    "        surf = pygame.image.fromstring(raw_data, size, \"RGB\")\n",
    "        screen.blit(surf, (0, 0))\n",
    "        pygame.display.flip()\n",
    "\n",
    "    def get_obs(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.Footprint = nx.DiGraph()\n",
    "        self.Footprint.add_node(start)\n",
    "        nodeattr = self.graph.graph.nodes[start].copy()\n",
    "        nx.set_node_attributes(self.Footprint, {start: nodeattr})\n",
    "        self.successorsLst = nx.dfs_successors(G=self.graph.graph, source=start, depth_limit=1)[start]\n",
    "        #self.action_space = MultiDiscrete([len(self.successorsLst), 100, 10])\n",
    "        self.action_space = MultiDiscrete([7, 100, 10])\n",
    "        self.observation_space = Dict({'route': Discrete(7), 'Speed': Discrete(100), 'Duration': Discrete(10), 'pathDistance': Box(low=0, high=30000, shape=(1,), dtype=float)})\n",
    "        self.current_place = start\n",
    "        self.route_state = {'footprint': self.Footprint, 'route': [start], 'Speed': [], 'Duration': []}\n",
    "        self.previous_place = None\n",
    "        self.route_length = 16\n",
    "        self.state = {'route': locations.index(start), 'Speed': 0, 'Duration': 0, 'pathDistance': 0}\n",
    "        return self.state\n",
    "\n",
    "    def retrieve_location(self, action):\n",
    "        location = self.successorsLst[action[0]]\n",
    "        return\n",
    "\n",
    "envR = Routing(Graph=graph1, Ship=ship, start=start)\n",
    "#envR.reset()\n",
    "\n",
    "# episodes = 5\n",
    "# for episode in range(1, episodes +1):\n",
    "#     done = False\n",
    "#     obs = envR.reset()\n",
    "#     score = 0\n",
    "#     length = 16\n",
    "#     while not done:\n",
    "#         if not isinstance(envR.current_place, End):\n",
    "#             successors = nx.dfs_successors(G=envR.graph.graph, source=envR.current_place, depth_limit=1)\n",
    "#             #print('current_place', envR.current_place.name)\n",
    "#             envR.successorsLst = successors[envR.current_place]\n",
    "#             #print([loc.name for loc in envR.successorsLst])\n",
    "#             location_mask = [1 if loc in envR.successorsLst else 0 for loc in locations]\n",
    "#         else:\n",
    "#             successors = nx.dfs_successors(G=envR.graph.graph, source=start, depth_limit=1)\n",
    "#             envR.successorsLst = successors[start]\n",
    "#             location_mask = [1 if loc in envR.successorsLst else 0 for loc in locations]\n",
    "#         print('location mask:', location_mask)\n",
    "#         print('successors:', envR.successorsLst)\n",
    "#         action = envR.action_space.sample(mask=(np.array(location_mask, dtype=np.int8), np.ones((100,), dtype=np.int8), np.ones((10,), dtype=np.int8)))\n",
    "#         action = envR.action_space.sample()\n",
    "#         print('action chosen:', action[0])\n",
    "#         obs, reward, done, info = envR.step(action)\n",
    "#         envR.render()\n",
    "#         score += reward\n",
    "#     print('episode:{} distance:{}'.format(episode, reward))\n",
    "# envR.close()\n",
    "\"\"\"\"\"\"\n",
    "envR = FlattenObservation(envR)\n",
    "\n",
    "log_path = os.path.join('../Training', 'Logs')\n",
    "model_path = os.path.join('../Training', 'Model', 'NOMask_25000stepModel')\n",
    "model = PPO('MlpPolicy', env=envR, verbose=1, tensorboard_log=log_path)\n",
    "time_start = time.time()\n",
    "model.learn(total_timesteps=25000)\n",
    "time_finish = time.time()\n",
    "training_time = time_finish - time_start\n",
    "print('Trianing time:', training_time)\n",
    "model.save(model_path)\n",
    "\"\"\"\n",
    "model_path = os.path.join('Training', 'Model', 'reward_modified10kstepModel')\n",
    "model = PPO.load(model_path, env=envR)\n",
    "eva = evaluate_policy(model, envR, n_eval_episodes=100, render=False)\n",
    "print(eva)\n",
    "\"\"\"\n",
    "episodes = 30\n",
    "score_list = []\n",
    "for episode in range(1, episodes +1):\n",
    "    done = False\n",
    "    obs = envR.reset()\n",
    "    length = 16\n",
    "    #print(obs)\n",
    "    while not done:\n",
    "        envR.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        #print('obs', obs)\n",
    "        #print('action chosen:', action[0])\n",
    "        obs, reward, done, info = envR.step(action)\n",
    "    print('episode:{} distance:{}'.format(episode, reward))\n",
    "    score_list.append(reward)\n",
    "envR.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
